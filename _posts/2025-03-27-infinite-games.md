---
layout: default
title: "infinite-games"
date: 2025-03-27
---

# Infinite Games

Communication is an infinite game.

Consciousness is a peculiar form of communication that is distinguished by its ability to mediate the establishment of communication between different computational processes that share resources but that otherwise may have significantly different internal structure.

My goal is to mathematically describe this process of reciprocal, open-ended communication.

## Introduction

To begin, I will sketch some intuitive characteristics of consciousness, viewed in this light as a medium to facilitate the establishment of communication channels beginning from shared data streams.

- **Functionality**. In brains, consciousness plays a functional role. Among other roles, it enables the recognition and response to a broad palette of novelty, to new newness, and perhaps even newly new newness, rather than mere difference.
- This role is consistent with the interpretation of consciousness as integrative (e.g., a crucial characteristic shared by GWT and its inbred relative IIT); a more alert, more conscious being can compare any two given stimuli (of which it is consciously aware). This ability is remarkable, because it enables composisional generalization (the ability to combine (pieces) of known knowledge or concepts with those of any other, despite any dissimilarities whatsoever; give me two things, and I can think of them at once and thereby at least produce a (possibly nonsense!) Frankenstein combination. Any two things separately thinkable are jointly imaginable, subject only to the limits of working memory, which are least restrictive when one is most conscious, that is -- most awake.)
  - Note: Why is it that consciousness seems to be particularly helpful for flexibly binding and unbinding symbols, e.g., when I substitute values into an equation, or more abstractly, when I substitute an equation into itself? [Add simple logic ref, perhaps from Godel's Proof.] Why is it that lucid dreamers struggle read in their dreams?
- Consciousness's integrative ability goes beyond Hebbian learning or the generitically wired and behaviorally refined pathways of white matter. Again, it is the possibility of combining in intensity two or more experiences that have never been jointly experienced before. (Note: sidesteps for now the possibility that such combinations can be explored latently by background neural processes, esp. dreaming, which serves an annealing funciton among many others.)
- What makes such novel combinations possible? I claim that such an extreme ability to integrate requires inference-time adaptation. In order for two brain areas which do not know about one another to communicate in ways they never have before, consciousness must not merely provide the bandwidth for their signals to reach one another; it must also facilitate (at inference time) the formation of reciprocal representations (of B in A and of A in B).
- In order to communicate deliberately rather than merely be a machinic broadcaster of a signal, B must model itself. It must be able to decode it own output at least somewhat. Otherwise communication would be at best a shot in the dark. Before A and B have established communication, they must have methods for parsing and decoding their own outputs that are independent of one another. A (B) must model data_A (data_B) using resources that are unkown to B (A).
- An implication: to parse `data_B`, A must model B: A must not only `model(data_B)` but also `model(self_B(data_B))` because B must already contain and run `self_B(data_B)` in order to communicate deliberately.
- Computational structure: there are functional limits to what A can known or actively model about itself; therefore it will have incomplete knowledge of the implementations of the subroutines that are invoked in modeling either itself or B.
- These subroutines need not be and cannot in general be guaranteed to be strictly controlled by B, as this would require 1) a level of knowledge that is infeasible, and 2) a level of segreation of neuronal activity that is unrealistic. (When I am thinking about a spider, there is always a small chance that I will think about a birthday hat.) The upshot:
- Subroutines can call other subroutines and also their own invokers. The process of running model(data_B) can recursively recruit an ensemble of subproutines that, in their attempts to implement parts of model(dataB), may find their own errors too large and therefore recruit an expanding ensemble.
- So far, this process describes the qualia of open-ended awareness, such as e.g., paying attention to wildlife: there is a sense in which their, once attention is glued to them, they in fact control your mind, because their own actions do not merely send your brain raw data, but rather now send data that is parsed through actively engaged simulators; we see them through our errors and the subprocesses those errors spawn. Those things that cannot be classified or delegated to any automatic subprocess simply exist as the shimmering edge of reality they have exposed us to in our naked awareness of novelty. This is a recurrent processing model in which I have framed Deleuze's account of difference. That is, consciousness exits to provide a medium which in principle allows one to compare not against all established variations in the world, but rather (simply, modestly) all internal variations unknown by the "thinker's" mind yet encodable and simulatable via automatic processes that exist in the thinker's brain. That which cannot be automatic focuses us directly on the world as distilled into it, and thereby at least permits the formation of new simulations, although how this happens is, at least for now, impossible to say in detail: by necessity, it is a "passive synthesis," with the emphasis on passive.


From an intuitive point of view, such an ability requires consciousness to concurrently form and match simulations of the recipient of its attention; that is, for process A to attend consciously to process B, A must open a channel of communication to a form of input from B whose raw data are observable but whose meaning is unkown. In order to process this data, A must already implicitly simulate B; that is, to the extent that A can parse B's data at all, A must *already* contain processes that can invert B's processessing and therefore must resemble it. However, in the case of interest, namely establishing novel contact, such preliminary observations will leave large stretches of B's data indecipherable. Thus, the simulations of the inverse data generating process must be refined, and it may be that more (modularly) independent simulations must be formed inside of A in order to most thoroughly decipher B's data. It can also happen that, while A initially allocates only a certain amount of computational resources to modeling B, the errors in such a process necessitate the allocation of new resources. 


TO DO:

Notes on phenomenology / other theories of consciousness

.

Reading list:
- Shannon (Communication)
- Shannon (Noise)
- Crooks Fluctuation Theorem
- Jeremy England - Biology of Life
- 
- Assembly Theory
- 

Further leads:
- Activte Inference (Friston)
  - Perhaps this can be promoted to Interactive Inference.
- Spin Glass Theory and the Replica Trick
- Kard Vol II. (Statistical Physics of Fields)
- Field theory of neural networks

