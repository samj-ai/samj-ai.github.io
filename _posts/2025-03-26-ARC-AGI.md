---
layout: default
title: "ARC-AGI"
date: 2025-03-26
---

# **ARC-AGI** is solvable.

# 0. The challenge

Compositional generalization is a key feature of human intelligence. Given a few pieces and a few ways of combining them, young children can entertain themselves endlessly building an infinite array of ever-more-complex combinations. Something inside every human being wants to combine things in new ways for the joy of witnessing the novel product. We do this like breathing.

LLMs (esp. non-reasoning models) do not handle compositional generalization well. For various architectural reasons (esp. attention), and the dynamics of SGD training with a next-token objecive, autoregressive transformers typically decline to learn compositional representations of their training data and instead elect to represent it iconically through several redundant memories of data points and attentions patterns. At inferrence time, these redundant representations are ensembled depending on the model's inferred task context.

This emergent method of information processing is highly data-inefficient, much in the way that a student who learns math by rote ultimately needs many more examples to learn any new application of the knowledge they have ostensibly acquired. It also prevents models from gaining the kind of self-knowledge that humans acquire when they deliberate on how to select and combine their mental skills in a novel context: LLMs don't know how they do what they do -- and until they can, they will necessarily be unable to gain the very human kind of self-knowledge regarding how much to trust that their own skills will function when combined in a new setting for deployment. Compositional generalization matters.

How can we measure this skill and improve it?

Operationalizations about. None is perfect. Some are useful. Some are useful and beautiful, for example, these three:

- ARC-AGI
- SRaven
- Szpakowksi concepts

Ultimately all such examples can be subsumed in math, situated as special cases of the larger sandboxes of patterns that professional mathematicians create -- and decoate, and expand -- for their recreation. While it is less aesthetic, then, I will also include BBH, a hard benchmark of mathematics reasoning problems.

# 1. Test-time training

Compositional generalization directly promotes sample efficiency; they are inseparable. Several approaches are possible to promote greater sample-efficiency:

- Metalearning and metacognition
- Transductive learning
- Extended "reasoning" (CoT)
- RL / curiosity-based methods
- Hypernetworks
- Reasoning models (test-time compute)
- ...

I'll revisit these idesas in section 2. For now, I want to describe an approach that used test-time training to achieves good results on the ARC-AGI dataset.

## 1.1

In *The Surprising Effectiveness of Test-Time Training* (https://arxiv.org/abs/2411.07279), the authors deploy a combination of technqiues well adapted to the structured, compositional, and data-scarce setting of ARC-AGI.

The idea of test-time training is to update the weights of the model by training on a dataset `D_{TTT}` of examples created at test-time -- in fact, this dataset will be made fresh and trained on any time the model is asked to make a new prediction. The core of method is how to much such a dataset (and train on it -- and infer from it).

To this end, it is useful to frame ARC-AGI as an [in-context learning (ICL)](https://functions.baulab.info) task. That is, each task in ARC-AGI is a collection of examples of input-output pairs, 

```
T_k = {(x_1, y_1), (x_2, y_2), ..., (x_Nk, y_Nk), y_{Nk+1}}
```

together with a final unpaired "test" input $x_{N_k+1}$. the goal is to successfully predict the output of the test input by inferring the single rule that maps every example input to its respective output -- and then to correctly apply that rule to the test input.

Here's one ARC task from the paper - the authors are happy that their methods improve on ICL baselines. By the way -- it's a nice rule, isn't it? How would you write a small program that implemented the rule's IO function $x \mapsto y$?

**dataset example**

<img 
    src="/assets/images/arc-example.png" 
    alt="Description" 
    style="
        width: 100%; 
        max-width: 800px; 
        height: auto; 
        display: block; 
        margin: 0 auto;
    "
/>

The core idea is that it is possible to train on the dataset of ICL examples for any ICL task. Given a task `T_k` with `N_k` IO pairs to demonstrate it, we can make a dataset of `N_k - 1` ICL tasks, where each task is just the original ICL problem but omitting one pair `(x_i, y_i)` and using `y_i` as the ground truth prediction target.

***training***
For each task:

- Make a dataset of examples using the leave-one-out idea.
  - Augment this dataset using invertible transformations: rotations, reflections, transpositions, color permutations, and input sequence permuations. (Note: maybe they should have used a [deep set](https://arxiv.org/abs/1703.06114) instead.)
- Minimize the CE loss on this dataset.
  - Note: for each example in the ICL dataset, they apply the loss to all the outputs, not only the output without ground truth in that batch.
  - Upate the parameters using a *different* LoRA adapter for each task.
- Do inference:
  - This is done with a two-stage hierarchical voting setup. Given a new example task with k demonstration IO pairs, a leave-one-out dataset is created. Each leave-one-out task with k sequences then has 1) each of the T transformations is applied, and 2) its sequence elements permuted randomly x2, for a total of 

``` 
n_predictions = k x T x 2 predictions
```

  - Then the *three* most frequent predicted outputs for each transformation advance to the second round of voting, from which the most frequent overall candidate is selected.

**Training pipeline**

<img 
    src="/assets/images/ttt.png" 
    alt="Description" 
    style="
        width: 100%; 
        max-width: 800px; 
        height: auto; 
        display: block; 
        margin: 0 auto;
    "
/>

***Details***

- The authors use Llama-3.2-1B, 3B, and 8B. All are the instruct finetuned models, and of course they use 8B for their final evaluations.
- **Important point:** The authors rely on extensive pretraining on a dataset of synthetic data created from programs that Michael Hodel wrote using a DSL he crafted specially for ARC. These [publicly available](https://github.com/michaelhodel/re-arc) programs are the correct and validated IO rules for ARC examples with ground truth solutions. Thus, these programs enables anyone to create every single valid IO pair for each ARC task. Moreover, by composing input-output functions for more than one task (and applying to larger input grids), one can even generate infinitely new ARC tasks, and generate (in principle) every valid IO pair for these as well. (See TTT appendix B, and Michael Hodel's paper [Addressing the Abstraction and Reasoning Corpus via Procedural Example Generation](https://arxiv.org/abs/2404.07353).) ***Is this cheating?***

# 2. Dimensions of growth

